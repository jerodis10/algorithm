1.알고리즘 설계 패러다임
    - 알고리즘을 설계하는 작업은 한순간의 영감보다는 여러 전략적인 선택에 따라 좌우
        - 알고리즘을 고안하기 위해서는 해결할 문제의 특성 이해
        - 동작 시간과 사용하는 공간 사이의 상충 관계 이해
        - 적절한 자료 구조 선택

    - 알고리즘 설계 패러다임 : 주어진 문제를 해결하기 위해 알고리즘이 채택한 전략이나 관점.
        - 어떤 알고리즘들은 문제를 해결하기 위한 가장 중요한 깨달음을 공유하는데, 이와 같은 깨달음을 모아 보면 일종의 패턴 확인 가능.


    1.1 무식하게 풀기
        - 모든 재귀 함수는 '더이상 쪼개지지 않는' 최소한의 작업에 도달했을 때 곧장 반환하는 조건문을 포함해야 함. -> 기저 사례
        - 입력이 잘못되거나 범위에서 벗어난 경우도 기저 사례로 택해서 맨 처음 처리 -> 반복적인 코드 제거

        [완전 탐색 레시피]
        1.완전 탐색은 존재하는 모든 답을 하나씩 검사하므로, 걸리는 시간은 가능한 답의 수에 정확히 비례.
          최대 크기의 입력을 가정했을 때 답의 개수를 계산하고 이들을 모두 제한 시간 안에 생성할 수 있을지 가늠.
          만약 시간 안에 계산할 수 없다면 다른 설계 패러다임 적용해야 함.
        2.가능한 모든 답의 후보를 만드는 과정을 여러 개의 선택으로 나눈다. 각 선택은 답의 후보를 만드는 과정의 한 조각이 됨.
        3.그중 하나의 조각을 선택해 답의 일부를 만들고, 나머지 답을 재귀 호출을 통해 완성.
        4.조각이 하나밖에 남지 않은 경우, 혹은 하나도 남지 않은 경우에는 답을 생성했으므로, 이것을 기저 사례로 선택해 처리.

        - 문제의 답이 하나가 아니라 여러 개이고, 그 중에서 어떤 기준에 따라 가장 '좋은' 답을 찾아 내는 문제들을 통칭해 최적화 문제.
            -> 완전 탐색은 최적화 문제를 풀기 위한 가장 직관적인 방법.
            ex) n개의 원소 중 r개를 순서 없이 골라내는 방법은 딱 하나, but n개의 사과 중 r개를 골라서 무게의 합을 최대화 -> 최적화


    1.2 분할 정복
        - 분할 정복 : 일반적인 재귀 호출과 다른 점은 문제를 한 조각과 나머지 전체로 나누는 대신 거의 같은 크기의 부분 문제로 나누는 것.
            - 문제를 더 작은 문제로 분할하는 과정(divide)
            - 각 문제에 대해 구한 답을 원래 문제에 대한 답으로 병합하는 과정(merge)
            - 더이상 답을 분할하지 않고 곧장 풀 수 있는 매우 작은 문제(base case)

        - 문제를 둘 이상의 부분 문제로 나누는 자연스러운 방법이 있어야 하며,
          부분 문제의 답을 조합해 원래 문제의 답을 계산하는 효율적인 방법이 있어야 한다.

        - 문제) 쿼드 트리 뒤집기 p.189
        - 문제) 울타리 잘라내기 p.195


    1.3 동적 계획법
        - 동적 계획법은 큰 의미에서 분할 정복과 같은 접근 방식을 의미. 동적 계획법과 분할 정복의 차이가 발생하는 부분은 문제를 나누는 방식.
        - 동적 계획법에서 어떤 부분 문제는 두 개 이상의 문제를 푸는 데 사용될 수 있기에, 속도 향상을 꾀함.
        - 함수의 결과를 저장하는 장소를 마련해 두고, 한 번 계산한 값을 저장해 뒀다 재활용하는 최적화 기법을 메모제이션.
        - 참조적 투명성 : 입력이 고정되어 있을 때 그 결과가 항상 같은 함수.
        - 메모이제이션은 참조적 투명 함수의 경우에만 적용 가능.
            * int& ret = cache[a][b];  ->   cache가 다차원 배열일 때 유용. 인덱스의 순서를 바꿔 쓴다거나 하는 실수를 방지해줌.
        - 메모이제이션의 시간 복잡도 분석 : (존재하는 부분 문제의 수) * (한 부분 문제를 풀 때 필요한 반복문의 수행 횟수)

        [동적 계획법 레시피]
        1.주어진 문제를 완전 탐색을 이용해 해결.
        2.중복된 부분 문제를 한 번만 계산하도록 메모이제이션 적용.

        - 문제) 와일드카드 p.218

        [좀더 효율적인 동적 계획법 구현]
        1.완전 탐색으로 시작하기
            -> 점화식
        2.무식하게 메모이제이션 적용하기
            -> 배열의 크기가 입력으로 주어지는 숫자의 범위에 좌우, 특정 입력에 대해서 완전 탐색처럼 동작.
        3.입력 걸러내기
            -> 최적 부분 구조 (지금까지의 선택과 상관 없이 각 부분 문제를 최적으로 풀기만 하면 전체 문제의 최적해도 알 수 있음.)
        4-1.시작 위치 고정하기
        4-2.이분탐색 활용

        - 문제) 최대 증가 부분 수열 p.232

        [최적화 문제 동적 계획법 레시피]
        1.모든 답을 만들어 보고 그중 최적해의 점수를 반환하는 완전 탐색 알고리즘 설계.
        2.전체 답의 점수를 반환하는 것이 아니라, 앞으로 남은 선택들에 해당하는 점수만을 반환하도록 부분 문제 정의 바꾸기.
        3.재귀 호출의 입력에 이전의 선택에 관련된 정보가 있다면 꼭 필요한 것만 남기고 줄임. 문제에 최적 부분 구조가 성립할 경우에는 이전 선택
          에 관련된 정보를 완전히 없앨 수도 있음. 여기서 우리의 목표는 가능한 한 중복되는 문제를 많이 만드는 것. 입력의 종류가 줄어들면
          줄어들수록 더 많은 부분 문제가 중복되고, 따라서 메모이제이션을 최대한도로 활용 가능.
        4.입력이 배열이거나 문자열인 경우 가능하다면 적절한 변환을 통해 메모이제이션.

        - 문제) 합친 LIS p.236
        - 문제) 원주율 외우기 p.239
        - 문제) Quantization p.244
        - 문제) 삼각형 위의 최대 경로 개수 세기 p.254

        [경우의 수 계산하기 레시피]
        1.모든 답을 직접 만들어서 세어보는 완전 탐색 알고리즘을 설계. 이때 경우의 수를 제대로 세기 위해서는 재귀 호출의 각 단계에서 고르는 각
          선택지에 다음과 같은 속성이 성립해야 함.
            a)모든 경우는 이 선택지들에 포함.
            b)어떤 경우도 두 개 이상의 선택지에 포함되지 않음.
        2.최적화 문제를 해결할 때처럼 이전 조각에서 결정한 요소들에 대한 입력을 없애거나 변형해서 줄임. 재귀 함수는 앞으로 남아 있는 조각들을
          고르는 경우의 수만을 반환.
        3.메모이제이션 적용.

        - 문제) 비대칭 타일링 p.259
        - 문제) 폴리오미노 p.264


    1.4 동적 계획법 테크닉
        1) 최적화 문제의 실제 답 계산하기
            - 문제) 최대 증가 부분 수열 실제 출력 p.280

            [최적화 문제 답 계산하기 레시피]
            1.재귀 호출의 각 단계에서 최적해를 만들었던 선택을 별도의 배열에 저장.
            2.별도의 재귀 함수를 이용해 이 선택을 따라가며 각 선택지를 저장하거나 출력.

            - 문제) 여행 짐 싸기 p.281

        2) k번째 답 계산하기
            - 문제) 모스 부호 사전 p.293
                -> 모든 신호 만들기
                -> k-1 개 건너뛰기
                -> 좀더 똑똑하게 건너뛰기 (이항계수 활용)
                -> 좀더 깔끔하게 구현

            [k번째 답 계산하기 레시피]
            1.답들을 사전순서대로 만들며 경우의 수를 세는 완전탐색 알고리즘을 설계하고, 메모이제이션을 적용해 경우의 수를 세는
              동적 계획법 알고리즘으로 바꿈.
            2.모든 답들을 사전순으로 생성하며 skip개를 건너뛰고 첫 번째 답을 반환하는 재귀 호출 함수 구현. 재귀 함수는 각 조각들에 들어갈 수
              있는 값을 하나씩 고려하면서 이 값을 선택했을 떄 만들어지는 답의 수 M과 건너 뛰어야 할 답` 의 수 skip을 비교.
             a) M < skip : M 개의 답은 모두 우리가 원하는 답보다 앞에 있으므로, 이들을 건너뜀. 대신 skip을 M만큼 줄임.
             b) M > skip : M 개의 답 중에 우리가 원하는 답이 있으므로, 이 값을 선택. M 개의 답 중에 skip 개를 건너뛴 것이 우리가 원하는
                답. 이 값을 답에 추가하고 재귀 호출로 답의 나머지 부분을 만든다.

            - 문제) 드래곤 커브 p.306

        3) 정수 이외의 입력에 대한 메모제이션
            - 연관 배열 사용하기
            - 일대일 대응 함수 작성하기
                - 입력이 불린 값의 배열인 경우
                - 입력이 순열인 경우
                - 입력의 범위가 좁을 경우

            * 6.7 여행하는 외판원 문제 p.167
                -> 메모제이션을 하기 위해서는 지금까지 한 선택들에 대한 정보를 최소한만 받도록 함수의 정의를 고쳐야 한다. p.319

            - 문제) 실험 데이터 복구하기 p.327

        4) 조합 게임
            - 게임 트리 전체를 그린 후 밑에서부터 승패를 판단하면서 올라가는 bottom up 알고리즘은 직관적이지만 구현하기가 영 까다롭다.
              실제 게임 트리에서는 상태가 그림처럼 예쁘게 구분되지 않을 수도 있고, 맨 아래 줄에서 게임이 일제히 종료하는 것이 아니라 그 전에
              끝날 수도 있다. 메모리도 많이 차지함. 따라서 이 대신 흔히 구현하는 것이 top down 알고리즘

            - 문제) 틱택토 p.337
            - 문제) 숫자 게임 p.340
            - 문제) 블록 게임 p.344

        * 반복적 동적 계획법
            - bottom up 구조
            - 경우에 따라 공간 복잡도를 줄이는 데 쓸 수 있다. -> 슬라이딩 윈도 활용

            - 재귀적 동적 계획법의 장단점
                [장점]
                    - 좀더 직관적인 코드를 짤 수 있다.
                    - 부분 문제 간의 의존 관계나 계산 순서에 대해 고민할 필요가 없다.
                    - 전체 부분 문제 중 일부의 답만 필요할 경우 더 빠르게 동작한다.
                [단점]
                    - 슬라이딩 윈도 기법을 쓸 수 없다.
                    - 스택 오버플로를 조심해야 한다.

            - 반복적 동적 계획법의 장단점
                [장점]
                    - 구현이 대개 더 짧다.
                    - 재귀 호출에 필요한 부하가 없기 때문에 조금 더 빠르게 동작한다.
                    - 슬라이딩 윈도 기법을 쓸 수 있다.
                [단점]
                    - 구현이 좀더 비직관적이다.
                    - 부분 문제간의 의존 관계를 고려해 계산되는 순서를 고민해야 한다.

            - 문제) 회전초밥 p.355
            - 문제) 지니어스 p.359 ?


    1.5 탐욕법
        - 모든 선택지를 고려해 보고 그중 전체 답이 가장 좋은 것을 찾는 완전 탐색이나 동적 계획법과 달리, 탐욕법은 각 단계마다 지금 가장 좋은
          방법만을 선택.
        - 탐욕법은 지금의 선택이 앞으로 남은 선택들에 어떤 영향을 끼칠지는 고려하지 않는다.

        [탐욕적 알고리즘이 사용되는 경우]
        1.탐욕법을 사용해도 항상 최적해를 구할 수 있는 문제를 만난 경우, 탐용법은 동적 계획법보다 수행 시간이 훨씬 빠르기 때문에 유용.
        2.시간이나 공간적 제약으로 인해 다른 방법으로 최적해를 찾기 너무 어렵다면 최적해 대신 근사해를 찾는 것으로 타협할 수 있다.
          탐욕법은 이럴 때 최적은 아니지만 임의의 답보다는 좋은 답을 구하는 용도로 유용하게 쓰인다.
        * 주로 1번만 사용됨.

        * 최적해를 얻을 수 있는 접근이 직관적이지 않은 경우도 많기 때문에 실수에 더 유의해야 함.

        [탐욕적 알고리즘의 정당성 증명]
        1.탐욕적 선택 속성
            - 답의 모든 부분을 고려하지 않고 탐욕적으로만 선택하더라도 최적해를 구할 수 있다.
        2.최적 부분 구조
            - 부분 문제의 최적해에서 전체 문제의 최적해를 만들 수 있다.
                (이 속성은 대부분 자명해서 따로 증명할 필요가 없는 경우가 대부분.)

        - 문제) 회의실 예약 p.370

        * 탐욕법을 사용하는 이유는 동적 계획법에 필요한 메모리나 시간이 과도하게 크기 때문.

        - 문제) 출전 순서 정하기 p.375

        [탐욕적 알고리즘 레시피]
        1.문제의 답을 만드는 과정을 여러 조각으로 나눈다.
        2.각 조각마다 어떤 우선순위로 선택을 내려야 할지 결정한다. 이에 대한 직관을 얻기 위해서는 예제 입력이나 그 외의 작은 입력을 몇 개
          손으로 풀어보는 것이 효율적.
        3.어떤 방식이 동작할 것 같으면 두 가지의 속성을 증명
          a)탐욕적 선택 속성: 항상 각 단계에서 우리가 선택한 답을 포함하는 최적해가 존재함을 보이면 된다. 이 증명은 대개 우리가 선택한 답과
            다른 최적해가 존재함을 가정하고, 이것을 조작해서 우리가 선택한 답을 포함하는 최적해로 바꿀 수 있음을 보이는 형태로 이루어짐.
          b)최적 부분 구조: 각 단계에서 최적의 선택만을 했을 때 전체 최적해를 구할 수 있는지 여부를 증명. 다행히도 대개의 경우 이 속성이
            성립하는지 아닌지는 자명하게 알 수 있다.

        - 문제) 도시락 데우기 p.376
        - 문제) 문자열 합치기 p.380


2.기초 자료 구조
    - 거의 모든 자료 구조는 추상화, 최적화를 하기 위한 것.
        - 추상화 : 현실 세계에 존재하는 개념이나 구조를 간결화해 컴퓨터 프로그램에 사용되는 자료 구조로 표현하는 과정.
            -> 우리가 현실 세계에서 사용하는 개념이나 언어들은 프로그램으로 직접 작성하기에는 너무 모호하고 많은 정보를 담고 있기 때문에,
               이를 프로그램으로 직접 구현하기가 번거롭고 어렵다. 현실 세계의 개념을 추상화한 자료 구조는 개념에서 중요한 뼈대만을 뽑아내
               이름을 붙이고, 명확한 정의들을 곁들여 사람들이 쉽게 사용할 수 있도록 한다.
            -> 프로그래머는 내부 구현을 신경 쓸 필요 없이 좀더 높은 단계에서 생각할 수 있게 된다.
            -> 추상화를 위한 자료 구조들은 자료를 좀더 알아보기 쉽고, 이해하기 쉬운 형태로 저장하기 위한 고민의 결과물.

        - 최적화 : 프로그램의 동작 속도를 빠르게 하기 위한 것.


    2.1 비트마스크
        - 현대의 모든 CPU는 이진수를 이용해 모든 자료를 표현한다. 내부적으로 이진수를 사용하는 컴퓨터들은 이진법 관련 연산들을 아주 빨리
          할 수 있다.
        - 이와 같은 특성을 이용해 정수의 이진수 표현을 자료 구조로 쓰는 기법이 비트마스크
        - 비트마스크는 자료구조라고 말할 수는 없지만 종종 굉장히 유용하게 사용됨.

        [장점]
        1.더 빠른 수행 시간 : 비트마스크 연산은 O(1)에 구현되는 것이 많기 때문에, 적절히 사용할 경우 다른 자료 구조를 사용하는 것보다
                           훨씬 빨리 동작한다.
        2.더 간결한 코드 : 다양한 집합 연산들을 반복문 없이 한 줄에 쓸 수 있기 때문에 비트마스크를 적절히 사용하면 굉장히 짧은 코드 작성.
        3.더 작은 메모리 사용 : 더 적은 메모리를 사용한다는 말은 더 많은 데이터를 미리 계산해서 저장해 둘 수 있다. 더 많은 데이터를 미리
                            계산해 둘 수 있으면 프로그램도 빨라지고, 더 적은 메모리를 사용하는 프로그램은 일반적으로 캐시 효율도 더 좋다.
        4.연관 배열을 배열로 대체

        [유의할 점]
        1.비트마스크를 사용하는 식에는 가능한 한 괄호를 자세하게 추가하는 습관을 들이는 것이 좋다.
            -> &, |, ^ 등의 비트 연산자의 우선순위는  == 혹은 != 등의 비교 연산자보다 낮다.
        2.64비트 정수를 비트마스크로 사용할 때 발생하는 오버플로우.
            -> 식 1<<b 에서 b가 32 이상이면 오버플로우 발생.
            -> 1 뒤에 이 상수가 부호 없는 64비트 정수임을 알려주는 접미사 ull을 붙여줘야 한다.
        3.부호 있는 정수형의 사용
            -> 음수를 오른쪽으로 시프트할 때 왼쪽 끝 비트들이 0이 아니라 1로 채워진다든지 하는 버그 발생
            -> 변수의 모든 비트를 다 쓰고 싶을 때는 부호 없는 정수형을 쓰는 것이 좋다.


        2.1.1 비트마스크를 이용한 집합의 구현
            - 공집합과 꽉 찬 집합 구하기
                ex) int fullPizza = (1 << 20) - 1;

            - 원소 추가
                ex) toppings |= (1 << p);

            - 원소의 포함 여부 확인
                if(toppings & (1 << p) == 1) cout << "pepperoni is in" << endl;

                 * & 연산의 결과값이 0 또는 1<<p 라는 점에 유의.

            - 원소의 삭제
                ex) toppings -= (1 << p);
                    -> 이 코드는 이미 페퍼로니가 토핑 목록에 있을 때만 사용할 수 있다.
                ex) toppings &= ~(1 << p);

            - 원소의 토글
                ex) toppings ^= (1 << p);

            - 두 집합에 대해 연산하기
                ex) int added = (a | b);
                    int intersection = (a & b);
                    int removed = (a & ~b);
                    int toggled = (a ^ b);

            - 집합의 크기 구하기
                ex) int bitCount(int x){
                        if(x == 0) return 0;
                        return x % 2 + bitCount(x / 2);
                    }
                ex) java - Integer.bitCount(toppings);

            - 최소 원소 찾기
                ex) java - Integer.numberOfTrailingZeros(toppings)
                    -> 이 연산들 역시 대개 CPU 명령어로 곧장 치환돠거나, 다양한 최적화가 적용된 코드를 사용하기 때문에 굉장히 빠르다.
                ex) int firstToppings = (toppings & -toppings);

            - 최소 원소 지우기
                ex) toppings &= (toppings - 1);
                ex) 최하위 비트를 지웠을 때 0이 된다면 주어진수는 2의 거듭제곱.
                    -> 2의 거듭제곱 값들은 이진수 표현에서 켜진 비트가 하나밖에 없다.

            - 모든 부분 집합 순회하기
                ex) for(int subset = pizza; subset; subset = ((subset-1) & pizza)) { }
                    -> subset은 pizza의 부분집합.


        2.1.2 비트마스크의 응용 예제
            - 예제) 에라토스테네스의 체 p.586 ?
            - 예제) 15퍼즐 상태 표현하기 p.587 ?
            - 예제) O(1) 우선순위 큐 p.588 ?
            - 예제) 극대 안정 집합 p.589
            - 예제) 졸업 학기 p.590 ?


    2.2 선형 자료 구조
        - 동적 배열과 연결리스트 : 두 자료 구조는 배열과 비슷하지만, 배열에서 비효율적이거나 할 수 업사는 작업들을 효율적으로 할 수 있도록
                               도와준다.

        - 문제) 조세푸스 문제 p.620


    2.3 큐와 스택, 데크
        - 일렬로 늘어선 자료들을 표현하는 자료 구조

        - 문제) 스택을 사용해 울타리 자르기 문제를 해결하는 스위핑 알고리즘 p.628 ?
        - 문제) 짝이 맞지 않는 괄호 p.633
        - 문제) 외계 신호 분석 p.635


3. 트리
    - 본래 트리는 계층 관계를 갖는 객체들을 표현하기 위해 만들어진 자료구조이다. 그러나 사실 트리는 실제 계층 관계가 없는 자료들을 트리로
      표현해서 같은 연산을 더 빠르게 할 수 있는 경우가 많다.

    3.1 트리의 구현과 순회
        * 자료구조
            - 추상형 자료 구조
                - 스택, 큐
            - 탐색형 자료 구조
                - 트리
                    - 이진 탐색 트리, 힙, 구간 트리
                - 해시

        - 문제) 트리 순회 순서 변경 p.686
        - 문제) 요새 p.689


    3.2 이진 검색 트리
        - 검색 트리는 연결리스트나 큐처럼 자료들을 담는 컨테이너지만, 자료들을 일정한 순서에 따라 정렬한 상태로 저장.
        - 이진 트리 : 각 노드가 왼쪽과 오른쪽, 최대 두 개의 자식 노드만을 가질 수 있는 트리.
        - 이진 검색 트리 : 각 노드의 왼쪽 서브트리에는 해당 노드의 원소보다 작은 원소, 오른쪽 서브트리에는 큰 원소.
        - 순회 - 이진 검색 트리를 중위 순회하면 크기 순서로 정렬된 원소의 목록을 얻을 수 있다.
        - 트리를 중위 순회하면 정렬된 결과를 얻을 수 있다는 말은, 집합에 포함된 최대 원소나 최소 원소를 쉽게 얻을 수 있다는 말.
          왼쪽 끝 -> 최소,  오른쪽 끝 -> 최대
        - 기울어진 이진 트리의 단점을 개선한 것 중 하나가 균형 잡힌 이진 검색 트리.
          트리 구조에 추가적인 제약을 정하고 이 제약이 만족되도록 노드들을 옮겨서 트리의 높이가 항상 O(lgN)이 되도록 유지.
          대표적인 예로 레드-블랙 트리 -> 대부분의 표준 라이브러리에서 제공하는 이진 검색 트리의 구현도 이 트리 사용.

        - 문제) 너드인가, 너드가 아닌가 2  p.702

        - 균형 잡힌 이진 검색 트리 직접 구현하기: 트립
            - 트립은 입력이 특정 순서로 주어질 때 그 성능이 떨어진다는 이진 검색 트리의 단점을 해결하기 위해 고안된 일종의 랜덤화된 이진 검색 트리


    3.3 우선순위 큐와 힙
        - 부모 노드가 가진 원소는 항상 자식 노드가 가진 원소 이상. 힙에서 대소 관계 규칙은 이진 검색 트리와 달리 부모 자식 관계에만 적용됨.
        - 왼쪽 자식과 오른쪽 자식이 갖는 원소의 크기는 제한하지 않는다.
        - 마지막 레벨을 제외한 모든 레벨에 노드가 꽉 차 있어야 한다.
        - 마지막 레벨에 노드가 있을 때는 항상 가장 왼쪽부터 순서대로 채워져 있어야 한다.

        - 배열을 이용한 힙의 구현
        - 새 원소의 삽입3
        - 최대 원소 꺼내기

        - 문제) 변화하는 중간 값 p.731


4. 그래프
    - 객체들의 상호 관계를 표현하기 위해 고안된 자료 구조.
    - 그래프는 어떤 상호 관계도 표현할 수 있으므로, 계층 관계만을 표현하는 트리에 비해 훨씬 다양한 현실 세계의 문제를 표현할 수 있다.


    4.1 그래프의 표현과 정의
        - 예) 철도망의 안정성 분석, 소셜 네트워크 분석, 인터넷 전송 속도 계산, 한 붓 그리기, 외환 거래
        - 예) 할 일 목록 정리(위상 정렬), 15-퍼즐, 게임판 덮기(이분 그래프), 회의실 배정(만족성 문제, 2-SAT)
        - 희소 그래프에 대해서는 인접 리스트, 밀집 그래프에 대해서는 인접 행렬
            - 간선의 수가 V*V 에 비해 훨씬 적은 그래프를 희소 그래프, 많으면 밀집 그래프


    4.2 그래프의 깊이 우선 탐색
        - 문제) 고대어 사전 p.831

        - 오일러 서킷
            - 그래프의 모든 간선을 정확히 한 번씩 지나서 시작점으로 돌아오는 경로
            - 모든 정점이 짝수점이면서, 간선들이 하나의 컴포넌트에 포함된 그래프가 주어질 때 항상 오일러 서킷을 찾아낼 수 있다.

        - 오일러 트레일
            - 그래츼 모든 간선을 정확히 한 번씩 지나지만, 시작점과 끝점이 다른 경로

        - 문제) 단어 제한 끝말잇기 p.842
            - 해밀토니안 경로
                - 그래프의 모든 정점을 정확히 한 번씩 지나는 경로
                - 큰 그래프에 대해 해밀토니안 경로를 빠르게 찾는 방법은 아직 고안되지 않음
                - 해밀토니안 경로를 찾는 유일한 방법은 조합탐색 -> 최악의 경우 n!개의 후보 생성

            - 방향 그래프에서의 오일러 서킷
                - 각 정점에 들어오는 간선의 수와 나가는 간선의 수가 같아야 한다. 이 외의 조건은 무향그래프와 동일.

        - 간선의 분류
            - 트리 간선: 스패닝 트리에 포함된 간선.
            - 순방향 간선: 스패닝 트리의 선조에서 자손으로 연결되지만 트리 간선이 아닌 간선.
            - 역방향 간선: 스패닝 트리의 자손에서 선조로 연결되는 간선.
            - 교차 간선: 위 세 가지 분류를 제외한 나머지 간선.

            -> 간선의 분류는 그 자제가 유용하기보다는 그래프 알고리즘을 이해하고 증명하기 위한 도구로 유용하게 쓰임.

            - 예제) 위상 정렬의 정당성 증명 p.851
            - 예제) 사이클 존재 여부 확인하기 p.852

            - 간선을 구분하는 방법
                - (u, v)가 순방향 간선이라면 v는 u의 자손이어야 한다. 따라서 v는 u보다 더 늦게 발견되어야 함.
                - (u, v)가 역방향 간선이라면 v는 u의 선조여야 한다. 따라서 v는 u보다 일찍 발견되어야 함.
                - (u, v)가 교차 간선이려면 dfs(v)가 종료한 후 dfs(u)가 호출되어야 함. 따라서 v는 u보다 일찍 발견되어야 함.

            - 예제) 절단점 찾기 알고리즘 p.854
                - 무향 그래프에서 절단점을 포함하지 않는 서브그래프를 이중 결합 컴포넌트라 부른다.
                - 이중 결합 컴포넌트 내에서는 임의의 한 정점을 그래프에서 지우더라도 장점 간의 연결 관계가 유지된다.

            - 예제) 다리 찾기 p.857
                - 어떤 간선을 삭제했을 때 이 간선을 포함하던 컴포넌트가 두 개의 컴포넌트로 쪼개질 경우 이 간선을 다리라고 부른다.

            - 예제) 강결합 컴포넌트 분리 p.858
                - 이중 결합 컴포넌트(무향 그래프에서만 정의)와 비슷하지만 방향 그래프에서 정의되는 개념.
                - 원 그래프의 정점들을 SCC별로 분리하고 각 SCC를 표현하는 정점들을 갖은 새로운 그래프를 만드는 과정을 그래프의 압축.

                - 강결합 컴포넌트 분리를 위한 타잔의 알고리즘

            - 문제) 감시 카메라 설치 p.864


    4.3 그래프의 너비 우선 탐색
        - 예제) 너비 우선 탐색 p.883
            - 깊이 우선 탐색에서는 각 정점의 방문 여부를 저장했던 것에 비해, 너비 우선 탐색은 각 정점의 발견 여부를 저장.
        - 너비 우선 탐색은 대개 최단 경로 문제 푸는 데 사용됨.

        - 문제) Sorting Game p.886

        - 최단 경로 전략
            - 예제) 15-퍼즐 p.900
                - 효율성 분석 -> 너비 우선 탐색의 시간 복잡도는 O(V + E)지만, 이 문제에서는 대략 O(b 지수d)
            - 양방향 탐색 p.902
            - 점점 깊어지는 탐색 p.906
                - 프로그램이 요구하는 메모리가 컴퓨터가 가지고 있는 물리적 메모리 양을 넘어가기 시작하면 시간보다 메모리가 소중해짐.
                - 시간이야 프로그램을 좀더 오래 수행하면 되니 비교적 유연하게 사용량을 늘릴 수 있지만, 메모리는 그렇게 쉽게 늘렸다
                  줄였다 할 수 없다.
                - 따라서 규모가 큰 탐색 문제를 풀 때는 깊이 우선 탐색을 기반으로 한 방법을 사용해야 한다.
                - 깊이 우선 탐색은 앞으로 방문할 정점의 목록을 유지하는 너비 우선 탐색과는 달리 정점을 발견하는 즉시 방문.

            [탐색 방법 선택하기]
            1.상태 공간에서의 최단 경로를 찾는 경우, 너비 우선 탐색을 최우선적으로 고려한다. 너비 우선 탐색은 직관적이고 구현하기도 간단.
              탐색의 깊이 한계가 정해져 있지 않거나 너무 깊어서 메모리 사용량이 너무 크지 않은지 확인 필요.
            2.상태 공간에서의 최단 경로를 찾는데, 탐색의 최대 깊이가 정해져 있고 너비 우선 탐색을 하기에는 메모리와 시간이 부족할 경우
              양방향 탐색 고려. 단 이 경우 목표 상태에서 역방향으로 움직이기가 쉬워야 한다.
            3.두 탐색이 모두 너무 메모리를 많이 사용하거나 너무 느린 경우, 최적화를 할 거리가 더 많은
              점점 깊어지는 탐색을 사용할 수밖에 없다.

            - 문제) 하노이의 탑 p.912


        4.4 최단 경로 알고리즘
            - 가중체가 없는 그래프에 대한 최단 경로는 29장에서 다룬 너비 우선 탐색으로 찾을 수 있기 때문에, 이 절에서는 가중치가 있는
              그래프 위에서의 최단 경로를 찾는 알고리즘.
            - 그래프에 대한 최단 경로 문제를 해결하려 할 때 가장 먼저 유의해야 할 점은 그래프에 음수 가중치를 갖는 간선이 있는지 여부.
            - 음수 사이클이 있는 경우 최단 경로 문제는 제대로 정의되지 않는다.
            - 최단 경로 알고리즘들은 크게 단일 시작점 알고리즘과 모든 쌍 알고리즘으로 나뉜다.
            - 이 절에서 다루는 최단 거리 알고리즘들은 모두 방향그래프를 기준으로 동작. 무방향 그래프 위에서의 최단 경로를 찾기 위해서는
              각각의 양방향 간선을 두 개의 일방 통행 간선으로 쪼개서 방향 그래프로 만들어야 한다.

            4.4.1 다익스트라 알고리즘
                - 단일 시작점 최단 경로 알고리즘
                - 실제 구현 p.923
                - 동작 과정 p.924
                - 정당성 증명 p.927

                - 문제) 신호 라우팅 p.930
                - 문제) 소방차 p.933

            4.4.2 벨만-포드 알고리즘
                - 단일 시작점 최단 경로 알고리즘이지만, 음수 간선이 있는 그래프에 대해서도 최단 경로를 찾을 수 있으며, 그래프에
                  음수 사이클이 있어서 최단 거리가 제대로 정의되지 않을 경우 이것도 알려준다.
                - 시작점에서 각 정점까지 가는 최단 거리의 상한을 적당히 예측한 뒤 예측값과 실제 최단 거리 사이의 오차를 반복적으로
                  줄여가는 방식으로 동작.

                - 종료 조건과 정당성의 증명 p.943
                - 음수 사이클의 판정 p.945

                - 문제) 시간여행 p.948

            4.4.3 플로이드 알고리즘
                - 모든 쌍 간의 최단 경로 알고리즘
                - 프로토 타입 구현 p.954
                - 메모리 사용량 줄이기 p.955
                - 실제 경로 계산하기 p.957

                - 문제) 음주 운전 단속 p.959
                - 문제) 선거 공약 p.963
















